{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge is to classify urban sounds from 4-second sound files. There are 10 possible classifications. The dataset provided includes 8729 training examples and 8731 unlabled sound files for testing. I like this problem because I'm a bit of an audiophile, and I want to try my hand at a neural network. \n",
    "\n",
    "I'll train a neural network to classify the sounds. First, I'll use the librosa library to load in the audio files and extract features (the different distinct frequencies in the audio file).  Then, I'll encode the labels using scikit-learn's LabelEncoder().  I'll use Keras to build model, keeping it as simple as possible for now (3 layers, using standard paramaters). Then I will evaluate the model using the test data set.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Loading and encoding data. \n",
    "I'll install librosa (for dealing with audio files) and import libraries, then load data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>drilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID         Class\n",
       "0   0         siren\n",
       "1   1  street_music\n",
       "2   2      drilling\n",
       "3   3         siren\n",
       "4   4      dog_bark"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jackhammer          668\n",
       "engine_idling       624\n",
       "siren               607\n",
       "dog_bark            600\n",
       "street_music        600\n",
       "air_conditioner     600\n",
       "drilling            600\n",
       "children_playing    600\n",
       "car_horn            306\n",
       "gun_shot            230\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have about 600 examples of most sound types, about half that of car horn recordings, and about a third that of gun shots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will load the audio files using librosa.  I'll define a function that will allow me to apply the data to a data frame with the IDs and labels. \n",
    "\n",
    "Some explanation of the choices for processing audio data: \n",
    "1. Setting res_type to kaiser_fast speeds up loading the data, at a loss of quality. \n",
    "2. MFCC stands for Mel-frequency cepstral coefficients, it is a technique for extrating features based on frequency from the raw adio data. \n",
    "3. librosa.load returns a matrix (technically an mumpy.ndarray of size (n_mfcc, T) where T denotes the track duration in frames)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/Train'\n",
    "\n",
    "def parse_sound(row):\n",
    "\n",
    "    file_name = os.path.join('data/Train', str(row.ID) + '.wav')\n",
    "\n",
    "    try:\n",
    "        y, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
    "    except Exception as e:\n",
    "        print(\"Error while parsing file: \", file)\n",
    "        return None, None\n",
    "  \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to get a visual confirmation of what this function does.  So, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.5095695e+01,  1.2961186e+02, -3.2669899e+01,  1.5285441e+01,\n",
       "       -2.3782072e+00,  1.4626383e+01, -3.7646337e+00,  1.7962053e+01,\n",
       "       -2.0119922e+00,  1.4395791e+01, -1.1574688e+00,  8.6595840e+00,\n",
       "       -3.7047443e+00,  3.3922620e+00, -6.3679357e+00,  8.1460260e-02,\n",
       "       -8.7272234e+00,  6.9419968e-01, -5.4218426e+00,  2.7331510e+00,\n",
       "       -1.5587350e+00,  1.5997877e+00, -2.7055860e+00,  4.3276987e+00,\n",
       "       -2.0708835e+00,  4.9955597e+00, -1.8933897e+00, -2.1113320e-01,\n",
       "       -4.2716827e+00,  1.5992585e+00, -3.1662819e+00,  1.9053738e+00,\n",
       "       -3.3244791e+00,  8.2804763e-01, -2.8830101e+00,  1.4041675e+00,\n",
       "       -1.0563265e+00,  1.2371618e+00, -4.3638902e+00,  7.2084457e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_audio, sample_rate = librosa.load(os.path.join('data/Train', '0.wav'))\n",
    "mfcc = np.mean(librosa.feature.mfcc(y=y_audio, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These outputs are numerical values for each feature (think of the raw audio as what you hear from a whole choir, and the features are the a representation of each singer's voice for a given time interval, here, 1/10 of a second. It's really pulling out sound waves at different frequencies). \n",
    "\n",
    "Numerical values are our input to the ML model! It's just like the numerical representation of light intensity of a given color in a given pixel, in the context of computer vision.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the extracted feature data to the ID and label data. This takes a while... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrain = train\n",
    "ttrain['mfccs'] = train.apply(parse_sound, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>mfccs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>siren</td>\n",
       "      <td>[[-82.12359, 139.50595, -42.430847, 24.82786, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>street_music</td>\n",
       "      <td>[[-15.744001, 124.11996, -29.42888, 39.44719, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>drilling</td>\n",
       "      <td>[[-123.393654, 15.181944, -50.093338, 7.141871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>siren</td>\n",
       "      <td>[[-213.2787, 89.323616, -55.256165, 12.632097,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>[[-237.9265, 135.90247, 39.26844, 21.24023, 9....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID         Class                                              mfccs\n",
       "0   0         siren  [[-82.12359, 139.50595, -42.430847, 24.82786, ...\n",
       "1   1  street_music  [[-15.744001, 124.11996, -29.42888, 39.44719, ...\n",
       "2   2      drilling  [[-123.393654, 15.181944, -50.093338, 7.141871...\n",
       "3   3         siren  [[-213.2787, 89.323616, -55.256165, 12.632097,...\n",
       "4   4      dog_bark  [[-237.9265, 135.90247, 39.26844, 21.24023, 9...."
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttrain = ttrain[['ID', 'Class', 'mfccs']]\n",
    "ttrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unresolved question: are these normally distributed? do they need normalization? do they need regularization? --adress this in next version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the mfcc data to X, labels to y, test mfcc data to test_X.  Encode labels as numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "X = np.array(ttrain.mfccs.tolist())\n",
    "y = np.array(ttrain.Class.tolist())\n",
    "\n",
    "\n",
    "# encode labels as numbers\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##construct a neural network model!\n",
    "\n",
    "Notes on hyperparameter choice:\n",
    "1. 3 layers, one input, one hidden, one output. \n",
    "2. input layer shape is 40 because thre are 40 mel-frequency cepstral coeficients, one for each tenth of a second, in each sound file.  Output layer shape is 10 because there are 10 possible labels (actually, i have it calcualte that value).  The hidden layer is \n",
    "3. Activation = relu in the first two layers, Activation = softmax for output layer because thats what we need for multi-class classification.  All outputs sum to 1. \n",
    "4. Set dropout to 0.2 at start\n",
    "5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "n_obs = len(X)\n",
    "\n",
    "# build model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, input_dim=40))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_20_input to have shape (40,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-25911cea7b0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_20_input to have shape (40,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=32, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat encoding procedure for the test data\n",
    "def parse_sound(row):\n",
    "\n",
    "    file_name = os.path.join('data/Test', str(row.ID) + '.wav')\n",
    "\n",
    "    try:\n",
    "        y, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
    "    except Exception as e:\n",
    "        print(\"Error while parsing file: \", file)\n",
    "        return None, None\n",
    "  \n",
    "    return mfccs\n",
    "\n",
    "y_audio, sample_rate = librosa.load(os.path.join('data/Train', '0.wav'))\n",
    "mfcc = np.mean(librosa.feature.mfcc(y=y_audio, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "mfcc\n",
    "\n",
    "test['mfccs'] = test.apply(parse_sound, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>mfccs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[-76.2993, 20.437246, -17.56602, 26.38778, -22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[-375.73608, 149.91734, -21.467178, 14.365269,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>[-150.61726, -26.240969, -24.232021, 15.293082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>[-233.55365, 99.5192, -39.737137, 19.140862, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>[-74.35853, 107.8869, -15.967571, 34.601448, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3292</td>\n",
       "      <td>8708</td>\n",
       "      <td>[-50.20128, 59.27453, -78.98673, -10.342589, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3293</td>\n",
       "      <td>8718</td>\n",
       "      <td>[-373.61032, 86.03685, -50.425705, 11.193534, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3294</td>\n",
       "      <td>8719</td>\n",
       "      <td>[-123.03433, 98.71788, -5.6134286, 37.629673, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3295</td>\n",
       "      <td>8730</td>\n",
       "      <td>[-201.69658, 93.59071, -80.860405, -15.039109,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3296</td>\n",
       "      <td>8731</td>\n",
       "      <td>[-271.51474, 135.73033, -9.027784, 2.6885016, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3297 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                              mfccs\n",
       "0        5  [-76.2993, 20.437246, -17.56602, 26.38778, -22...\n",
       "1        7  [-375.73608, 149.91734, -21.467178, 14.365269,...\n",
       "2        8  [-150.61726, -26.240969, -24.232021, 15.293082...\n",
       "3        9  [-233.55365, 99.5192, -39.737137, 19.140862, -...\n",
       "4       13  [-74.35853, 107.8869, -15.967571, 34.601448, -...\n",
       "...    ...                                                ...\n",
       "3292  8708  [-50.20128, 59.27453, -78.98673, -10.342589, -...\n",
       "3293  8718  [-373.61032, 86.03685, -50.425705, 11.193534, ...\n",
       "3294  8719  [-123.03433, 98.71788, -5.6134286, 37.629673, ...\n",
       "3295  8730  [-201.69658, 93.59071, -80.860405, -15.039109,...\n",
       "3296  8731  [-271.51474, 135.73033, -9.027784, 2.6885016, ...\n",
       "\n",
       "[3297 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
